---
layout: post
section-type: post
title: Python爬虫
category: tech
tags: [ 'tutorial' ]
---

1 设置请求消息头(headers)

在使用python爬虫爬取数据的时候，经常会遇到一些网站的反爬虫措施，一般就是针对于headers中的User-Agent，如果没有对headers进行设置，User-Agent会声明自己是python脚本,而如果网站有反爬虫的想法的话，必然会拒绝这样的连接。而修改headers可以将自己的爬虫脚本伪装成浏览器的正常访问，来避免这一问题。

查看headers：F12 - ‘Network’ - ‘name’
```
headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Accept-Language": "zh-CN,zh;q=0.8",
            "Connection": "keep-alive",
        }
```

2 中文乱码

F12 - ‘Elements’ - ‘<head><meta charset=''><>’

```
response.enconding = ''
```