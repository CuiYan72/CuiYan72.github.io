---
layout: post
section-type: post
title: Python爬虫
category: tech
tags: [ 'tutorial' ]
---

一、模拟登录（无验证码）

首先建立session：```requests.session()```然后进入到登录界面，查看元素（用户名和密码），这里是"username"="username","password"="password"。将其写入到payload中，再查看元素（登录按钮），着重看“表单”部分，是哪种请求，action为向何处提交表单数据，可直接拼接在主页后面，作为URL。
```
<form name="login" method="POST" action="processlogin.4n6">
```
二、部分代码

1 requests.post()
```
payload={
	"username"="username",
	"password"="password",
}
requests.post('xxx/processlogin.4n6',data=payload)

```

2 requests.get
```
payload={}
requests.get(url，params=payload)
```
3 response 

简单来说：  

取文本，可以使用```response.text``` 

取图片，文件，可以使用```response.content```

4 BeautifulSoup

解析页面  

(1) 打开本地网页  

soup = BeautifulSoup(open('a.html'))  

(2) 直接打开网页  

soup = BeautifulSoup('response.text','html5lib')
```
<tr><td rowspan=3 align="center" valign="middle"><a href="download.4n6?sample=7d3efe923a838a753a26ae85e8e7263a2364824c068af58c256484fc18b5f91e"><img src="images/cyberhazard.jpg" width=96 height=96 alt="Download" title="Download"></a></td><td>MD5</td><td>679b0fe9ce154bfd8d3f322c81d180e3</td></tr>
```
(3) 找到出现<tr>的地方  

tr = soup.tr  

(4) 找到<tr>中的a标签  

a = tr.find('a')  

(5) 获取a标签的属性和属性值  

a.attrs 得到一个字典 {href:}  

a[href] 得到一个字符串  


5 文件操作

(1) 遍历指定目录下的文件  

os.listdir(path)  

(2) 分离文件名与扩展名；默认返回(fname,fextension)元组，可做分片操作  

os.path.splittext(file)[1] #后缀名  
